{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BUlLuwZezqaM"
      },
      "source": [
        "# Final project: Temporal Link Prediction Model for Weighted Dynamic Networks\n",
        "\n",
        "Welcome to our final project, we utilize GCN GAN to create this project.\n",
        "\n",
        "In this version, the dataset that is used is USCB taken from the paper of _GCN-GAN_.\n",
        "\n",
        "The USCB is a link-quality dataset of a wireless mesh network. The hosts in the network systems can be described as the nodes in the dynamic networks.\n",
        "\n",
        "In the dataset of USCB, you can find 1005 files, of the edge list.\n",
        "In each file ther is three numbers:\n",
        "\n",
        "- [X] _The first:_ is the index of the source node\n",
        "- [X] _The second:_ is the index of the target node\n",
        "- [X] _The third:_ is the weight of the edge, while of curse the maximum is _Threshold of the maximum edge weight = max_thres._\n",
        "\n",
        "# Dataset:\n",
        "Our dataset was obtained from the [figshare](https://nih.figshare.com/search?q=:keyword:%20%22Citation%20data%22) platform. Specifically, we utilized the[iCite Database Snapshot 2020-04](https://nih.figshare.com/articles/dataset/iCite_Database_Snapshot_2020-04/12288581?file=22650896) for testing our model.\n",
        "\n",
        "Each snapshot in the dataset consists of three files:\n",
        "- `icite_metadata.zip`: This file contains the metadata of the articles, as explained in the accompanying documentation.\n",
        "- `icite_metadata.tar.gz: This file contains the same content as icite_metadata.zip.\n",
        "- `open_citation_collection.csv`: This file includes the PubMed ID (`pmid`) of articles and their corresponding references.\n",
        "\n",
        "\n",
        "In our project, we focused on two main components: the article ID in PubMed (`pmid`) and the references cited within each article. To ensure efficient execution of the code on the Colab platform, we performed data reduction. Specifically, we considered articles published in the year 2020, limited the scope to human-related subjects, and selected articles that both referenced other articles and were referenced by other articles. Subsequently, we generated a metadata file that captured the source and target nodes, representing the articles and their respective references. This metadata file effectively captured the overall topology of the nodes in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IWW06YfxvaY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#new compat import due to tensorflow old version not being supported on colab\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "#disabled v2 behavior to fix runtime bugs\n",
        "tf.disable_v2_behavior()\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzg0LkXR61Xu"
      },
      "source": [
        "# Function Declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VtQrIiTBAMD"
      },
      "outputs": [],
      "source": [
        "def creat_file_cition(file_path):\n",
        "    '''\n",
        "    This function reads the network snapshot of a specific time slice and\n",
        "    generates a file containing only the source node and the target node.\n",
        "    In this case, the source node represents an article,\n",
        "    and the target node represents a reference within the source node.\n",
        "    :param file_path: The file path of the snapshot.\n",
        "    '''\n",
        "    cition_file = open(txt_file_path, 'w')\n",
        "\n",
        "    # Open the CSV file for reading\n",
        "    with open(file_path, encoding=\"utf8\") as csvfile:\n",
        "        # Create a CSV reader object\n",
        "        csvreader = csv.reader(csvfile, delimiter=',')\n",
        "        # Use the next() function to skip the first row\n",
        "        next(csvreader)\n",
        "        # Iterate through each row in the CSV file\n",
        "        for row in csvreader:\n",
        "            src = int(row[0]) #Index of the source node\n",
        "            referances = row[22].strip().split() # get the referances of the article\n",
        "\n",
        "            for ref in referances:\n",
        "                tar = int(ref) #Index of the target node\n",
        "\n",
        "                # write the edge list to output file\n",
        "                cition_file.write('%d %d' % (src, tar))\n",
        "                cition_file.write('\\n')\n",
        "\n",
        "    cition_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KSDMpBjv_vc"
      },
      "outputs": [],
      "source": [
        "def read_data(time_index, node_num, max_thres):\n",
        "    '''\n",
        "    Function to read the network snapshot of specific time slice\n",
        "    and generate a random weight for each edge in the graph\n",
        "    :param time_index: index of time slice\n",
        "    :param node_num: number of nodes in the dynamic network\n",
        "    :param max_thres: threshold of the maximum edge weight\n",
        "    :return: adjacency matrix of the specific time slice\n",
        "    '''\n",
        "    print('Read network snapshot #%d'%(time_index))\n",
        "    # Initialize the adjacency matrix\n",
        "    curAdj = np.mat(np.zeros((node_num, node_num)))\n",
        "    # Read the network snapshot of current time slice\n",
        "\n",
        "    file_edgeList = open(path_colab + \"edgeList_%d.txt\"%(time_index), 'w')\n",
        "\n",
        "    # Open the CSV file for reading\n",
        "    with open(txt_file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            # src index of the source node\n",
        "            # tar index of the target node\n",
        "            src, tar = map(int, line.split())\n",
        "\n",
        "            if(src<node_num and tar<node_num):\n",
        "                # generate random weight between 0 to max_thres.\n",
        "                weight = random.uniform(0.1, max_thres)\n",
        "\n",
        "                # write the edge list to output file\n",
        "                file_edgeList.write('%d %d %f' % (src, tar, weight))\n",
        "                file_edgeList.write('\\n')\n",
        "\n",
        "                # Update the adjacency matrix\n",
        "                curAdj[src, tar] = weight\n",
        "                curAdj[tar, src] = weight\n",
        "    file_edgeList.close()\n",
        "    return curAdj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z58Bk9e6608O"
      },
      "outputs": [],
      "source": [
        "def var_init(m, n):\n",
        "    '''\n",
        "    Function to initialze the weight matrix\n",
        "    :param m: number of rows of the weight matrix\n",
        "    :param n: number of column of the weight matrix\n",
        "    :return: the initialized weight matrix\n",
        "    '''\n",
        "    # in_dim = size[0]\n",
        "    # w_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    # return tf.random_normal(shape=size, stddev=w_stddev)\n",
        "    init_range = np.sqrt(6.0 / (m+n))\n",
        "    initial = tf.random_uniform([m, n], minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def gen_noise(m, n):\n",
        "    '''\n",
        "    Function to generative noises with uniform discribution\n",
        "    :param m: number of rows of the noise matrix\n",
        "    :param n: number of columns of the noise matrix\n",
        "    :return: the noise matrix\n",
        "    '''\n",
        "    return np.random.uniform(0, 1., size=[m, n])\n",
        "    #return np.random.normal(0.5, 1, [m, n])\n",
        "\n",
        "def get_gcn_fact(adj):\n",
        "    '''\n",
        "    Function to calculate the GCN factor of a certain network snapshot\n",
        "    :param adj: the adjacency matrix of a specific network snapshot\n",
        "    :return: the corresponding GCN factor\n",
        "    '''\n",
        "    adj_ = adj + np.eye(node_num, node_num)\n",
        "    row_sum = np.array(adj_.sum(1))\n",
        "    d_inv_sqrt = np.power(row_sum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = np.mat(np.diag(d_inv_sqrt))\n",
        "    gcn_fact = d_mat_inv_sqrt*adj_*d_mat_inv_sqrt # The GCN factor\n",
        "\n",
        "    return gcn_fact\n",
        "\n",
        "def get_noise_inputs():\n",
        "    '''\n",
        "    Function to construct the noise input list of the generaive network's GCN units\n",
        "    :return: the noise list\n",
        "    '''\n",
        "    # Construct the noise input list of the generative network\n",
        "    noise_inputs = []\n",
        "    for i in range(window_size+1):\n",
        "        noise_inputs.append(gen_noise(node_num, node_num))\n",
        "    return noise_inputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X35pH5tK8WZh"
      },
      "source": [
        "## Function related to the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xZoZOGy8VpF"
      },
      "outputs": [],
      "source": [
        "def gen_net(noise_input_phs, gcn_fact_phs):\n",
        "    '''\n",
        "    Function to define the generative network\n",
        "    :param noise_input_phs: list of the noise inputs\n",
        "    :param gcn_fact_phs: list of the GCN factors\n",
        "    :return:\n",
        "        gen_output: the output of the generative network\n",
        "        LSTM_params: list of all the parameters in the LSTM hidden layer\n",
        "    '''\n",
        "    # +--------------------+\n",
        "    # GCN Input Layer -> LSTM Hidden Layer\n",
        "    gcn_outputs = [] # Tensor list of the GCN Units' output\n",
        "    for i in range(window_size+1):\n",
        "        noise = noise_input_phs[i]\n",
        "        gcn_fact = gcn_fact_phs[i]\n",
        "        gcn_wei = gcn_weis[i]\n",
        "        # +----------+\n",
        "        # Conduct the GCN operation\n",
        "        gcn_conv = tf.matmul(gcn_fact, noise)\n",
        "        gcn_output = tf.sigmoid(tf.matmul(gcn_conv, gcn_wei))\n",
        "        # +----------+\n",
        "        # Reshape the output of current GCN unit\n",
        "        gcn_output = tf.reshape(gcn_output, [1, node_num*gen_hid_num0])\n",
        "        # +----------+\n",
        "        # Add current output to the tensor list\n",
        "        gcn_outputs.append(gcn_output)\n",
        "    # +--------------------+\n",
        "    # LSTM Hidden Layer -> Output Layer\n",
        "    # LSTM_cells = tf.nn.rnn_cell.MultiRNNCell([tf.compat.v1.nn.rnn_cell.LSTMCell(node_num*gen_hid_num0)])\n",
        "    LSTM_cells = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(node_num*gen_hid_num0)])\n",
        "    with tf.variable_scope(\"gen_net\") as gen_net:\n",
        "        LSTM_outputs, states = tf.nn.static_rnn(LSTM_cells, gcn_outputs, dtype=tf.float32)\n",
        "        # Get the parameters of the generative network\n",
        "        LSTM_params = [var for var in tf.global_variables() if var.name.startswith(gen_net.name)]\n",
        "    # +--------------------+\n",
        "    # Output Layer\n",
        "    gen_output = tf.nn.sigmoid(tf.matmul(LSTM_outputs[-1], gen_output_wei) + gen_output_bias)\n",
        "\n",
        "    return gen_output, LSTM_params\n",
        "\n",
        "def disc_net(disc_input):\n",
        "    '''\n",
        "    Function to define the discriminative network\n",
        "    :param disc_input: the input of the discriminative network\n",
        "    :return:\n",
        "        disc_output: the output of the discriminative network\n",
        "        disc_logit: the output of the output layer (without activation function)\n",
        "        disc_params: the parameters of the discriminative network\n",
        "    '''\n",
        "    # Input layer -> hidden layer #1\n",
        "    disc_h1 = tf.nn.sigmoid(tf.matmul(disc_input, disc_wei1) + disc_bias1)\n",
        "    # Hidden layer #1 -> Output layer\n",
        "    disc_logit = tf.matmul(disc_h1, disc_wei2) + disc_bias2\n",
        "    disc_output = tf.nn.sigmoid(disc_logit)\n",
        "\n",
        "    return disc_output, disc_logit\n",
        "\n",
        "def get_wei_KL(adj_est, gnd):\n",
        "    '''\n",
        "    Function to calculate the edge weight KL divergence\n",
        "    :param adj_est: prediction result\n",
        "    :param gnd: ground-truth\n",
        "    :return: edge weight KL divergence\n",
        "    '''\n",
        "    sum_est = 0\n",
        "    for r in range(node_num):\n",
        "        for c in range(node_num):\n",
        "            sum_est += adj_est[r, c]\n",
        "    sum_gnd = 0\n",
        "    for r in range(node_num):\n",
        "        for c in range(node_num):\n",
        "            sum_gnd += gnd[r, c]\n",
        "    p = gnd/sum_gnd\n",
        "    q = adj_est/sum_est\n",
        "    edge_wei_KL = 0\n",
        "    for r in range(node_num):\n",
        "        for c in range(node_num):\n",
        "            cur_KL = 0\n",
        "            if q[r, c]>0 and p[r, c]>0:\n",
        "                cur_KL = p[r, c]*np.log(p[r, c]/q[r, c])\n",
        "            edge_wei_KL += cur_KL\n",
        "\n",
        "    return edge_wei_KL\n",
        "\n",
        "\n",
        "def get_mis_rate(adj_est, gnd):\n",
        "    mis_sum = 0\n",
        "    for r in range(node_num):\n",
        "        for c in range(node_num):\n",
        "            if (adj_est[r, c]>0 and gnd[r, c]==0) or (adj_est[r, c]==0 and gnd[r, c]>0):\n",
        "                mis_sum += 1\n",
        "    mis_rate = mis_sum/(node_num*node_num)\n",
        "\n",
        "    return mis_rate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J8bezG9_0rAu"
      },
      "source": [
        "# Defining Constant Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHuYG8WpveOj"
      },
      "outputs": [],
      "source": [
        "# Set the parameters of the dynamic network\n",
        "node_num = 50 # Number of nodes in the dynamic network 10993358\n",
        "# +----------------------------------------+\n",
        "\n",
        "time_num = 12 # Number of time slices\n",
        "# +----------------------------------------+\n",
        "\n",
        "window_size = 10 # Window size of the history network snapshot to be considered\n",
        "# +----------------------------------------+\n",
        "\n",
        "# The path from my drive\n",
        "path_colab = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "metadata_csv_path = path_colab + \"dataset/CITATIONS/04_2020_no_self_edges-filtered-citation_metadata.csv\"\n",
        "txt_file_path = path_colab + \"outputs/data-citation.txt\"\n",
        "\n",
        "# +----------------------------------------+\n",
        "\n",
        "max_thres = 2000 # Threshold of the maximum edge weight\n",
        "# +----------------------------------------+\n",
        "\n",
        "# Define the parameters of the nueral network\n",
        "pre_epoch_num = 1000 # Number of pre-training epoches\n",
        "epoch_num = 4000 # Number of training epoches\n",
        "# 4000 (UCSB) 5000 (KAIST)\n",
        "# +----------------------------------------+\n",
        "\n",
        "# Define the parameters of the generative network\n",
        "gen_hid_num0 = 1\n",
        "gen_hid_num1 = 64\n",
        "# +----------------------------------------+\n",
        "\n",
        "edge_error_threshold = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHMdvJWe9Yr0"
      },
      "outputs": [],
      "source": [
        "# paramerters for the GUI:\n",
        "pre_train_G_learning_rate = 0.005\n",
        "G_learning_rate = 0.001\n",
        "D_learning_rate = 0.001\n",
        "\n",
        "clip_bound_number = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUhnUTk-9oDu"
      },
      "outputs": [],
      "source": [
        "# GCN Input Layer -> LSTM hideen Layer\n",
        "gcn_weis = [] # List of the weighted matrixes of the GCN units\n",
        "for i in range(window_size+1):\n",
        "    gcn_weis.append(tf.Variable(var_init(node_num, gen_hid_num0)))\n",
        "# +-----+\n",
        "\n",
        "# LSTM Hidden Layer -> Output Layer\n",
        "gen_output_wei = tf.Variable(var_init(node_num*gen_hid_num0, node_num*node_num))\n",
        "gen_output_bias = tf.Variable(tf.zeros(shape=[node_num*node_num]))\n",
        "# +-----+\n",
        "\n",
        "# Parameter list of the generative network's output layer\n",
        "gen_output_params = [gen_output_wei, gen_output_bias]\n",
        "# +----------+\n",
        "\n",
        "# Define the parameters of the discriminative network\n",
        "disc_hid_num = 1024\n",
        "# Input Layer -> Hidden Layer 1\n",
        "disc_wei1 = tf.Variable(var_init(node_num*node_num, disc_hid_num))\n",
        "disc_bias1 = tf.Variable(tf.zeros([disc_hid_num]))\n",
        "# +-----+\n",
        "\n",
        "# Hidden Layer 1 -> Output Layer\n",
        "disc_wei2 = tf.Variable(var_init(disc_hid_num, 1))\n",
        "disc_bias2 = tf.Variable(tf.zeros([1]))\n",
        "# +-----+\n",
        "\n",
        "# Parameter list of the discriminative network\n",
        "disc_params = [disc_wei1, disc_bias1, disc_wei2, disc_bias2]\n",
        "# +---------+\n",
        "\n",
        "# Clipping bound for WGAN's traning process\n",
        "clip_ops = []\n",
        "for var in disc_params:\n",
        "    clip_bound = [-clip_bound_number, clip_bound_number]\n",
        "    clip_ops.append(\n",
        "        tf.assign(var, tf.clip_by_value(var, clip_bound[0], clip_bound[1]))\n",
        "    )\n",
        "clip_disc_wei = tf.group(*clip_ops)\n",
        "# +---------------------+\n",
        "\n",
        "# Define the TF placeholders\n",
        "gcn_fact_phs = [] # Placeholder list of the GCN factors\n",
        "noise_input_phs = [] # Placeholder list of the noise inpus\n",
        "for i in range(window_size+1):\n",
        "    gcn_fact_phs.append(tf.placeholder(tf.float32, shape=[node_num, node_num]))\n",
        "    noise_input_phs.append(tf.placeholder(tf.float32, shape=[node_num, node_num]))\n",
        "# +----------+\n",
        "\n",
        "gnd_ph = tf.placeholder(tf.float32, shape=(1, node_num*node_num)) # Placeholder of the ground-truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxt_21f8TDf"
      },
      "outputs": [],
      "source": [
        "# Construct the GAN\n",
        "gen_output, LSTM_params = gen_net(noise_input_phs, gcn_fact_phs)\n",
        "disc_real, disc_logit_real = disc_net(gnd_ph)\n",
        "disc_fake, disc_logit_fake = disc_net(gen_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6-nJ1cq_2-7"
      },
      "outputs": [],
      "source": [
        "# Define the loss functin for the pre-train process of the generative network\n",
        "pre_gen_loss = tf.reduce_sum(tf.square(gnd_ph - gen_output))\n",
        "\n",
        "# Difine the optimizer for the pre-train process of the generative network\n",
        "#pre_gen_opt = tf.train.AdamOptimizer().minimize(pre_gen_loss, var_list=(gcn_weis+LSTM_params+gen_output_params))\n",
        "pre_gen_opt = tf.train.RMSPropOptimizer(learning_rate = pre_train_G_learning_rate).minimize(pre_gen_loss, var_list=(gcn_weis+LSTM_params+gen_output_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiWxnhjQ_-wU"
      },
      "outputs": [],
      "source": [
        "# Define the loss functin for the pre-train process of the generative network\n",
        "gen_loss = -tf.reduce_mean(disc_logit_fake)\n",
        "#gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
        "\n",
        "# Difine the optimizer for the pre-train process of the generative network\n",
        "disc_loss = tf.reduce_mean(disc_logit_fake) - tf.reduce_mean(disc_logit_real)\n",
        "#disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1.-disc_fake))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r--SqwmaAIJo"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer for the generative network and the discriminative network\n",
        "disc_opt = tf.train.RMSPropOptimizer(learning_rate=G_learning_rate).minimize(disc_loss, var_list=disc_params)\n",
        "gen_opt = tf.train.RMSPropOptimizer(learning_rate=D_learning_rate).minimize(gen_loss, var_list=(gcn_weis+LSTM_params+gen_output_params))\n",
        "# 0.001, 0.001 (UCSB) 0.0005 0.0005 (KAIST)\n",
        "\n",
        "#gen_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(gen_loss, var_list=(LSTM_params+gen_output_params))\n",
        "#disc_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(disc_loss, var_list=disc_params)\n",
        "\n",
        "#disc_opt = tf.train.AdamOptimizer().minimize(disc_loss, var_list=disc_params)\n",
        "#gen_opt = tf.train.AdamOptimizer().minimize(gen_loss, var_list=(LSTM_params+gen_output_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ5QWpDH-sJ5"
      },
      "outputs": [],
      "source": [
        "avg_error = 0.0\n",
        "avg_KL = 0.0\n",
        "avg_mis = 0.0\n",
        "cal_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_EzLiDE_5BE"
      },
      "outputs": [],
      "source": [
        "error_array = []\n",
        "avg_KL_array = []\n",
        "avg_mis_array = []\n",
        "time_num_array = []\n",
        "\n",
        "incorrect_predictions = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5G5fw0kTCG1V"
      },
      "source": [
        "# Execute the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsjoDGxnCINd"
      },
      "outputs": [],
      "source": [
        "# generate the file with the edges (without weights)\n",
        "creat_file_cition(metadata_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kCy76Kh7lHmZ"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q-pwxloBAMdj"
      },
      "outputs": [],
      "source": [
        "for t in range(window_size, time_num-2): # was in the beggining\n",
        "    # Construct the GCN factor list of the generative network\n",
        "    gcn_facts = []\n",
        "    for k in range(t-window_size, t+1):\n",
        "        # Read and normalize the adjacency matrix\n",
        "        # adj = read_data(name_pre, k, node_num, max_thres)/max_thres\n",
        "        adj = read_data(k, node_num, max_thres)/max_thres\n",
        "        gcn_fact = get_gcn_fact(adj)\n",
        "        gcn_facts.append(gcn_fact)\n",
        "    # +--------------------+\n",
        "\n",
        "    # Construct the ground-truth vector\n",
        "    gnd = np.reshape(read_data(t+1, node_num, max_thres ), (1, node_num*node_num))\n",
        "#     gnd = np.reshape(read_data(name_pre, t+1, node_num, max_thres ), (1, node_num*node_num))\n",
        "\n",
        "#     non_zero_numbers = gnd[gnd != 0]\n",
        "#     print(non_zero_numbers)\n",
        "\n",
        "    gnd /= max_thres\n",
        "\n",
        "    # +----------------------+\n",
        "    # Pretrain the generative network\n",
        "    loss_list = []\n",
        "    for epoch in range(pre_epoch_num):\n",
        "        # Construct the noise input list of the generative network\n",
        "        noise_inputs = get_noise_inputs()\n",
        "        # +----------+\n",
        "\n",
        "        # Construct the placeholder feed dictionary\n",
        "        ph_dict = dict(zip(noise_input_phs, noise_inputs))\n",
        "        ph_dict.update(dict(zip(gcn_fact_phs, gcn_facts)))\n",
        "        ph_dict.update({gnd_ph: gnd})\n",
        "        _, pre_g_loss, pre_g_output = sess.run([pre_gen_opt, pre_gen_loss, gen_output], feed_dict=ph_dict)\n",
        "        loss_list.append(pre_g_loss)\n",
        "        if epoch%100==0:\n",
        "            print('Pre-Train #%d, G-Loss: %f'%(epoch, pre_g_loss))\n",
        "        if epoch>500 and loss_list[epoch]>loss_list[epoch-1] and loss_list[epoch-1]>loss_list[epoch-2]:\n",
        "            break\n",
        "\n",
        "    # +----------------------+\n",
        "    # Train the GAN\n",
        "    print('Train the GAN')\n",
        "    for epoch in range(epoch_num):\n",
        "        # Train the discriminative network\n",
        "        # Construct the noise input list of the generative network\n",
        "        noise_inputs = get_noise_inputs()\n",
        "        # +----------+\n",
        "\n",
        "        # Construct the placeholder feed dictionary\n",
        "        ph_dict = dict(zip(noise_input_phs, noise_inputs))\n",
        "        ph_dict.update(dict(zip(gcn_fact_phs, gcn_facts)))\n",
        "        ph_dict.update({gnd_ph : gnd})\n",
        "        _, d_loss = sess.run([disc_opt, disc_loss], feed_dict=ph_dict)\n",
        "        # +--------------------+\n",
        "        # Train the generative network\n",
        "        # Construct the noise input list of the generative network\n",
        "        noise_inputs = get_noise_inputs()\n",
        "        # +----------+\n",
        "\n",
        "        # Construct the placeholder feed dictionary\n",
        "        ph_dict = dict(zip(noise_input_phs, noise_inputs))\n",
        "        ph_dict.update(dict(zip(gcn_fact_phs, gcn_facts)))\n",
        "        #ph_dict.update({gnd_ph: gnd})\n",
        "        _, g_loss, g_output = sess.run([gen_opt, gen_loss, gen_output], feed_dict=ph_dict)\n",
        "        # +----------+\n",
        "        _ = sess.run(clip_disc_wei)\n",
        "        # +--------------------+\n",
        "        # Refine the generative network\n",
        "        # Construct the noise input list of the generative network\n",
        "        #noise_inputs = get_noise_inputs()\n",
        "        # +----------+\n",
        "        # Construct the placeholder feed dictionary\n",
        "        #ph_dict = dict(zip(noise_input_phs, noise_inputs))\n",
        "        #ph_dict.update(dict(zip(gcn_fact_phs, gcn_facts)))\n",
        "        #ph_dict.update({gnd_ph: gnd})\n",
        "        #_, pre_g_loss, pre_g_output = sess.run([pre_gen_opt, pre_gen_loss, gen_output], feed_dict=ph_dict)\n",
        "\n",
        "        # save the number of incorrect edges that above the edge_error_threshold\n",
        "        incorrect_predictions_parEpoch = []\n",
        "        for c in range(len(g_output[0])):\n",
        "            if abs(g_output[0, c] - gnd[0,c]) > edge_error_threshold:\n",
        "                incorrect_predictions_parEpoch.append(c)\n",
        "\n",
        "        incorrect_predictions.append(incorrect_predictions_parEpoch)\n",
        "\n",
        "        if epoch%100==0:\n",
        "            print('GAN-Train #%d, D-Loss: %f, G-Loss: %f'%(epoch, d_loss, g_loss))\n",
        "\n",
        "    # +--------------------+\n",
        "    # Conduct a prediction process\n",
        "    # Construct the GCN factor list of the generative network\n",
        "    gcn_facts = []\n",
        "    for k in range(t-window_size+1, t+2):\n",
        "        # Read and normalize the adjacency matrix\n",
        "        # adj = read_data(name_pre, k, node_num, max_thres)/max_thres\n",
        "        adj = read_data(k, node_num, max_thres)/max_thres\n",
        "        gcn_fact = get_gcn_fact(adj)\n",
        "        gcn_facts.append(gcn_fact)\n",
        "    # +----------+\n",
        "\n",
        "    # Construct the noise input list of the generative network\n",
        "    noise_inputs = get_noise_inputs()\n",
        "    # +----------+\n",
        "    # Construct the placeholder feed dictionary\n",
        "    ph_dict = dict(zip(noise_input_phs, noise_inputs))\n",
        "    ph_dict.update(dict(zip(gcn_fact_phs, gcn_facts)))\n",
        "    output = sess.run([gen_output], feed_dict=ph_dict)\n",
        "    # +----------+\n",
        "\n",
        "    # Reshape the prediction result\n",
        "    adj_est = np.reshape(output[0]*max_thres, (node_num, node_num))\n",
        "    adj_est = (adj_est+adj_est.T)/2\n",
        "    for r in range(node_num):\n",
        "        adj_est[r, r] = 0\n",
        "    for r in range(node_num):\n",
        "        for c in range(node_num):\n",
        "            if adj_est[r, c]<0.01:\n",
        "                adj_est[r, c] = 0\n",
        "\n",
        "    # gnd = read_data(name_pre, t+2, node_num, max_thres)\n",
        "    gnd = read_data(t+2, node_num, max_thres)\n",
        "\n",
        "\n",
        "#     print('adj_est')\n",
        "#     for r in range(node_num):\n",
        "#         for c in range(node_num):\n",
        "#             print('%.2f'%(adj_est[c, r]), end=' ')\n",
        "#     print()\n",
        "#     print('gnd')\n",
        "#     for r in range(node_num):\n",
        "#         for c in range(node_num):\n",
        "#             print('%.2f'%(gnd[r, c]), end=' ')\n",
        "#     print()\n",
        "\n",
        "    print('adj_est')\n",
        "    for r in range(node_num):\n",
        "        print('%.2f' % (adj_est[1, r]), end=' ')\n",
        "    print()\n",
        "    print('gnd')\n",
        "    for r in range(node_num):\n",
        "        print('%.2f' % (gnd[1, c]), end=' ')\n",
        "    print()\n",
        "\n",
        "#     print('adj_est')\n",
        "#     for r in range(50):\n",
        "#         print('%.2f' % (adj_est[1, r]), end=' ')\n",
        "#     print()\n",
        "#     print('gnd')\n",
        "#     for r in range(50):\n",
        "#         print('%.2f' % (gnd[1, c]), end=' ')\n",
        "    print()\n",
        "\n",
        "    time_num_array.append(int(t+2))\n",
        "\n",
        "    error = np.linalg.norm(gnd-adj_est, ord='fro')/(node_num*node_num)\n",
        "    error_array.append(error)\n",
        "    avg_error += error\n",
        "    print('#%d Error: %f' % (t+2, error))\n",
        "\n",
        "\n",
        "    edge_wei_KL = get_wei_KL(adj_est, gnd)\n",
        "    avg_KL_array.append(edge_wei_KL)\n",
        "    avg_KL += edge_wei_KL\n",
        "    print('#%d Edge Weight KL: %f' % (t + 2, edge_wei_KL))\n",
        "\n",
        "    mis_rate = get_mis_rate(adj_est, gnd)\n",
        "    avg_mis_array.append(mis_rate)\n",
        "    avg_mis += mis_rate\n",
        "    print('#%d Mismatch Rate: %f' % (t + 2, mis_rate))\n",
        "\n",
        "    print()\n",
        "\n",
        "    cal_count += 1\n",
        "\n",
        "    f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-rror.txt\", 'a+')\n",
        "    #f = open(\"+KAIST-LSTM_GAN_GCN-error.txt\", 'a+')\n",
        "    f.write('%d %f' % (t + 2, error))\n",
        "    f.write('\\n')\n",
        "    f.close()\n",
        "\n",
        "    f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-KL.txt\", 'a+')\n",
        "    #f = open(\"+KAIST-LSTM_GAN_GCN_KL.txt\", 'a+')\n",
        "    f.write('%d %f' % (t + 2, edge_wei_KL))\n",
        "    f.write('\\n')\n",
        "    f.close()\n",
        "\n",
        "    f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-mis.txt\", 'a+')\n",
        "    #f = open(\"+KAIST-LSTM_GAN_GCN-mis.txt\", 'a+')\n",
        "    f.write('%d %f' % (t + 2, mis_rate))\n",
        "    f.write('\\n')\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ak5eVLdf--R8"
      },
      "outputs": [],
      "source": [
        "# +--------------------+\n",
        "avg_error /= cal_count\n",
        "avg_KL /= cal_count\n",
        "avg_mis /= cal_count\n",
        "# +--------------------+\n",
        "f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-rror.txt\", 'a+')\n",
        "#f = open(\"+KAIST-LSTM_GAN_GCN-error.txt\", 'a+')\n",
        "f.write('Avg. Error %f' % (avg_error))\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "# +--------------------+\n",
        "f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-KL.txt\", 'a+')\n",
        "#f = open(\"+KAIST-LSTM_GAN_GCN_KL.txt\", 'a+')\n",
        "f.write('Avg. KL %f' % (avg_KL))\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "# +--------------------+\n",
        "f = open(path_colab + \"+ICITE-LSTM_GAN_GCN-mis.txt\", 'a+')\n",
        "#f = open(\"+KAIST-LSTM_GAN_GCN-mis.txt\", 'a+')\n",
        "f.write('Avg. Mis %f' % (avg_mis))\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "\n",
        "# GUI\n",
        "display(HTML(add_button_html_code))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DRvACAl0Dikr"
      },
      "source": [
        "### Identifying Inaccurate Edge Predictions in the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQn-9eiYDm4k"
      },
      "outputs": [],
      "source": [
        "def find_incorrect_predictions_edge(error_present):\n",
        "    # create a index array for the incorrect predictions of the edges.\n",
        "    # init the array in size of node_num:\n",
        "    index_arr = []\n",
        "    bad_edges_arr = {}\n",
        "    good_edges_arr = {}\n",
        "\n",
        "    num_good = 0\n",
        "    num_bad = 0\n",
        "\n",
        "    for i in range(node_num*node_num):\n",
        "        index_arr.append(0)\n",
        "    # create the index array:\n",
        "    for epoch in incorrect_predictions:\n",
        "        for pred in epoch:\n",
        "            index_arr[pred] += 1\n",
        "\n",
        "    # calculate the ever\n",
        "    total_iterations_gan = (time_num - 2 - window_size + 1) * epoch_num\n",
        "    for i in range (len(index_arr)):\n",
        "        index_arr[i] = index_arr[i] / total_iterations_gan\n",
        "\n",
        "    for i in range(node_num*node_num):\n",
        "        if(index_arr[i] < error_present):\n",
        "            if(index_arr[i] != 0):\n",
        "                num_good += 1\n",
        "                good_edges_arr[i//node_num] =  i%node_num\n",
        "            index_arr[i] = 0\n",
        "        else:\n",
        "            num_bad += 1\n",
        "            bad_edges_arr[i//node_num] =  i%node_num\n",
        "    return num_good, num_bad, bad_edges_arr, good_edges_arr\n",
        "\n",
        "\n",
        "num_good, num_bad, bad_edges_arr, good_edges_arr = find_incorrect_predictions_edge(0.0055)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CpuvN3a906A7"
      },
      "source": [
        "## Graph Output:\n",
        "\n",
        "The model's output includes the following:\n",
        "\n",
        "1. Graph of the final snapshot: This graph visually represents the network's final state. The dashed red edges indicate edges that the model predicted incorrectly, while the black edges represent edges that the model correctly predicted.\n",
        "\n",
        "2. Error graph: This graph illustrates the average error associated with each edge in the network. The error metric quantifies the disparity between the predicted and actual values for each edge.\n",
        "\n",
        "3. KL graph: This graph showcases the average Kullback-Leibler (KL) divergence for each edge in the network. KL divergence measures the difference between two probability distributions, indicating how much one distribution diverges from another.\n",
        "\n",
        "By analyzing these graphs, one can gain insights into the model's performance, identify incorrect predictions through the dashed red edges, assess the overall error level in the network using the Error graph, and evaluate the distribution dissimilarity through the KL graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vM0W54sEABR4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "for i in range(len(adj_est)):\n",
        "    for j in range(len(adj_est[i])):\n",
        "        if(adj_est[i][j] > 0):\n",
        "            G.add_edge(i, j)\n",
        "\n",
        "elarge = [(u, v) for (u, v, d) in G.edges(data=True) if v not in bad_edges_arr]\n",
        "esmall = [(u, v) for (u, v, d) in G.edges(data=True) if v in bad_edges_arr]\n",
        "\n",
        "pos = nx.spring_layout(G,k=9000, seed=8000)  # positions for all nodes - seed for reproducibility\n",
        "\n",
        "# nodes\n",
        "nx.draw_networkx_nodes(G, pos, node_size=300)\n",
        "\n",
        "# edges\n",
        "nx.draw_networkx_edges(G, pos, edgelist=elarge, width=2)\n",
        "nx.draw_networkx_edges(\n",
        "    G, pos, edgelist=esmall, width=2, alpha=0.5, edge_color=\"r\", style=\"dashed\"\n",
        ")\n",
        "\n",
        "# node labels\n",
        "nx.draw_networkx_labels(G, pos, font_size=11, font_family=\"sans-serif\")\n",
        "# edge weight labels\n",
        "edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.margins(-0.01)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"there are \", num_good, \" good eages, and \",num_bad, \"bad edges: \" )\n",
        "print(\"Good Edges:\", good_edges_arr)\n",
        "print(\"Bad Edges:\", bad_edges_arr)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FWReMXJZ1Fix"
      },
      "source": [
        "### Error Bar:\n",
        "Represents the error in precents between the predicted network is to the\n",
        "ground-truth network.\n",
        "\n",
        "### Avg KL:\n",
        "edge-wise KL-divergence to further consider the magnitude difference of link weights\n",
        "\n",
        "This value shows us the Kullback-Leibler divergence from each iteration,\n",
        "The KL value is parameter that tells us how similar the predicted network is\n",
        "to the ground-truth network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TrOF-LO1AB-1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Error linear graph:\n",
        "plt.title(\"Output Error\")\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Error')\n",
        "\n",
        "# Set the number of desired ticks on the y-axis\n",
        "num_ticks = 15\n",
        "plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(num_ticks))\n",
        "plt.plot(time_num_array, error_array, marker = 'o', c = 'r')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# KL linear graph:\n",
        "plt.title(\"Output Avg KL\")\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Avg KL')\n",
        "# Set the number of desired ticks on the y-axis\n",
        "num_ticks = 15\n",
        "plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(num_ticks))\n",
        "plt.plot(time_num_array, avg_KL_array, marker = 'o', c = 'g')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b1uOSCaw1Lrz"
      },
      "source": [
        "# GUI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r3MZ7fPLD7kD"
      },
      "source": [
        "## HTML Pages"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nT6cYmg0EABB"
      },
      "source": [
        "### Home page HTML code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KrDA_kp_AEnE"
      },
      "outputs": [],
      "source": [
        "# Define the HTML, CSS, and JavaScript code for the GUI\n",
        "Home_page_html_code = '''\n",
        "<style>\n",
        "    body {\n",
        "        font-family: Arial, sans-serif;\n",
        "        text-align: center;\n",
        "        padding-top: 50px;\n",
        "    }\n",
        "    h1 {\n",
        "        color: #333333;\n",
        "    }\n",
        "    button {\n",
        "        background-color: #2D7DF6;\n",
        "        color: white;\n",
        "        padding: 10px 20px;\n",
        "        font-size: 16px;\n",
        "        border: none;\n",
        "        cursor: pointer;\n",
        "        border-radius: 4px;\n",
        "    }\n",
        "</style>\n",
        "\n",
        "<h1>Temporal Link Prediction Model for Weighted Dynamic Networks</h1>\n",
        "<h2> This system is able to predict the validity of links within a given article. </h4>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1dAV0bMCa96_T1aNzT8OsRVcy6vUwM81I\" alt=\"home-page-img\" />\n",
        "\n",
        "<button onclick=\"handleButtonClick()\">Start Predict</button>\n",
        "\n",
        "<script>\n",
        "    // Function to handle button click\n",
        "    function handleButtonClick() {\n",
        "        google.colab.kernel.invokeFunction('open_Train_Prediction_DefineParams_Page', [], {});\n",
        "    }\n",
        "</script>\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o5hy9x6w_e5r"
      },
      "source": [
        "### Define parameters page HTML code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnTOTh-t__8H"
      },
      "outputs": [],
      "source": [
        "# Define the HTML, CSS, and JavaScript code for the GUI\n",
        "Define_params_page_html_code= '''\n",
        "<style>\n",
        "    body {\n",
        "        font-family: Arial, sans-serif;\n",
        "        text-align: center;\n",
        "        padding-top: 50px;\n",
        "    }\n",
        "    h1 {\n",
        "        color: #333333;\n",
        "    }\n",
        "    #paramsForm{\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "      gap: 50px;\n",
        "    }\n",
        "    .form-group {\n",
        "        margin-bottom: 20px;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        align-items: flex-start;\n",
        "    }\n",
        "    .form-group label {\n",
        "        display: block;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .form-group select {\n",
        "        width: 190px;\n",
        "        padding: 5px;\n",
        "        border-radius: 7px;\n",
        "        cursor: pointer;\n",
        "        border: 1px solid gray;\n",
        "    }\n",
        "    .form-group select:hover {\n",
        "        border: 1px solid black;\n",
        "    }\n",
        "    .form-group select option{\n",
        "      padding: 10px;\n",
        "    }\n",
        "    button {\n",
        "        background-color: #2D7DF6;\n",
        "        color: white;\n",
        "        padding: 10px 20px;\n",
        "        font-size: 16px;\n",
        "        border: none;\n",
        "        cursor: pointer;\n",
        "        border-radius: 4px;\n",
        "    }\n",
        "    .dataset-url-container{\n",
        "      padding: 25px;\n",
        "    }\n",
        "    .dataset-url-container label{\n",
        "      font-weight: bold;\n",
        "    }\n",
        "    .dataset-url-container input{\n",
        "      width: 638px;\n",
        "      padding: 5px;\n",
        "      border-radius: 6px;\n",
        "    }\n",
        "</style>\n",
        "\n",
        "<h1>Temporal Link Prediction Model for Weighted Dynamic Networks</h1>\n",
        "<h2>Train and Prediction Process</h1>\n",
        "<h4>Train the system to predict Link connection</h4>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1b336GpgLmcEiwfy0p-synq9GoaVHiuRN\" alt=\"progress-config\" width=\"150\" height=\"50\"/>\n",
        "\n",
        "  <div class=\"dataset-url-container\">\n",
        "    <label for=\"addDatasetLink\">Dataset Link:</label>\n",
        "    <input id=\"addDatasetLink\" type=\"url\" placeholder=\"/content/drive/MyDrive/Colab Notebooks/dataset/CITATIONS/04_2020_no_self_edges-filtered-citation_metadata.csv\" />\n",
        "  </div>\n",
        "<form id=\"paramsForm\">\n",
        "  <div class=\"form-left\">\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"numTimeSlice\">Num time slice:</label>\n",
        "        <select id=\"numTimeSlice\" name=\"numTimeSlice\">\n",
        "            <option value=\"1000\">1000</option>\n",
        "            <option value=\"500\">500</option>\n",
        "            <option value=\"400\">400</option>\n",
        "            <option value=\"350\">300</option>\n",
        "            <option value=\"200\">200</option>\n",
        "            <option value=\"100\">100</option>\n",
        "            <option value=\"50\">50</option>\n",
        "            <option value=\"13\">13</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"learningRatePreTrain\">Learning rate (G pre-train):</label>\n",
        "        <select id=\"learningRatePreTrain\" name=\"learningRatePreTrain\">\n",
        "            <option value=\"0.005\">0.005</option>\n",
        "            <option value=\"0.001\">0.001</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"learningRateG\">Learning rate (G):</label>\n",
        "        <select id=\"learningRateG\" name=\"learningRateG\">\n",
        "            <option value=\"0.001\">0.001</option>\n",
        "            <option value=\"0.005\">0.005</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"learningRateD\">Learning rate (D):</label>\n",
        "        <select id=\"learningRateD\" name=\"learningRateD\">\n",
        "            <option value=\"0.001\">0.001</option>\n",
        "            <option value=\"0.005\">0.005</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"clippingBound\">Clipping bound [-c, c]:</label>\n",
        "        <select id=\"clippingBound\" name=\"clippingBound\">\n",
        "            <option value=\"0.01\">0.01</option>\n",
        "        </select>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"form-right\">\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"numEpochsPreTrain\">Number of epochs (pre-train):</label>\n",
        "        <select id=\"numEpochsPreTrain\" name=\"numEpochsPreTrain\">\n",
        "            <option value=\"1000\">1000</option>\n",
        "            <option value=\"4000\">4000</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"numEpochsGAN\">Number of epochs (GAN):</label>\n",
        "        <select id=\"numEpochsGAN\" name=\"numEpochsGAN\">\n",
        "            <option value=\"4000\">4000</option>\n",
        "            <option value=\"1000\">1000</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"weightRange\">Weight range:</label>\n",
        "        <select id=\"weightRange\" name=\"weightRange\">\n",
        "            <option value=\"2000\">2000</option>\n",
        "            <option value=\"250\">250</option>\n",
        "            <option value=\"1\">1</option>\n",
        "            <option value=\"20000\">20000</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"randomNodes\">Random nodes:</label>\n",
        "        <select id=\"randomNodes\" name=\"randomNodes\">\n",
        "            <option value=\"50\">50</option>\n",
        "            <option value=\"29\">29</option>\n",
        "            <option value=\"500\">500</option>\n",
        "        </select>\n",
        "    </div>\n",
        "  </div>\n",
        "</form>\n",
        "\n",
        "<button onclick=\"handleButtonClick()\">Next</button>\n",
        "\n",
        "<script>\n",
        "    // Function to handle button click\n",
        "    function handleButtonClick() {\n",
        "        var form = document.getElementById('paramsForm');\n",
        "        var formData = new FormData(form);\n",
        "        var selectedOptions = {};\n",
        "\n",
        "        for (var pair of formData.entries()) {\n",
        "            selectedOptions[pair[0]] = pair[1];\n",
        "        }\n",
        "        var datasetURL = document.getElementById('addDatasetLink').value;\n",
        "        console.log([selectedOptions, datasetURL]);\n",
        "        google.colab.kernel.invokeFunction('open_Train_Prediction_RunNet_Page', [selectedOptions, datasetURL], {});\n",
        "    }\n",
        "</script>\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zI9DZ8gwGkfx"
      },
      "source": [
        "### Run Network Page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgHoxSB8a84b"
      },
      "outputs": [],
      "source": [
        "Run_Network_page_html_code = '''\n",
        "  <style>\n",
        "      body {\n",
        "          font-family: Arial, sans-serif;\n",
        "          text-align: center;\n",
        "          padding-top: 50px;\n",
        "      }\n",
        "      h1 {\n",
        "          color: #333333;\n",
        "      }\n",
        "    .loader {\n",
        "      border: 10px solid #2D7DF6;\n",
        "      border-color: #b3c6ff #c6b3ff #ecb3ff #ffb3ec;\n",
        "\n",
        "      margin: 10px;\n",
        "      display: inline-block;\n",
        "\n",
        "      border-radius: 5%;\n",
        "      width: 30px;\n",
        "      height: 30px;\n",
        "      -webkit-animation: spin 2s linear infinite; /* Safari */\n",
        "      animation: spin 3s linear infinite;\n",
        "    }\n",
        "\n",
        "    /* Safari */\n",
        "    @-webkit-keyframes spin {\n",
        "      0% { -webkit-transform: rotate(0deg); }\n",
        "      100% { -webkit-transform: rotate(360deg); }\n",
        "    }\n",
        "\n",
        "    @keyframes spin {\n",
        "      0% { transform: rotate(0deg); }\n",
        "      100% { transform: rotate(360deg); }\n",
        "    }\n",
        "\n",
        "\n",
        "    /* style the logs container: */\n",
        "    div.stream{\n",
        "      overflow-y: scroll;\n",
        "      overflow-x: hidden;\n",
        "      height: 400px;\n",
        "      display: flex;\n",
        "      border: 1px solid black;\n",
        "      justify-content: space-around;\n",
        "      border-radius: 15px;\n",
        "      padding: 20px;\n",
        "    }\n",
        "  </style>\n",
        "\n",
        "  <h1>Temporal Link Prediction Model for Weighted Dynamic Networks</h1>\n",
        "  <h3> Run the model, please wait it might take a while </h4>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1v39XibBE_TgdZbaxbVEAAM68CNXqk7h4\" alt=\"progress-prediction\" width=\"150\" height=\"50\"/>\n",
        "  <br/>\n",
        "  <div class=\"loader\"></div>\n",
        "\n",
        "  <h4> Logs:</h4>\n",
        "\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z3TDISVybazX"
      },
      "source": [
        "### Add button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kIQeVm_bgP5"
      },
      "outputs": [],
      "source": [
        "add_button_html_code = '''\n",
        "  <style>\n",
        "      button {\n",
        "          background-color: #2D7DF6;\n",
        "          color: white;\n",
        "          padding: 10px 20px;\n",
        "          margin: 20px;\n",
        "          font-size: 16px;\n",
        "          border: none;\n",
        "          cursor: pointer;\n",
        "          border-radius: 4px;\n",
        "      }\n",
        "\n",
        "      .loader {\n",
        "      -webkit-animation: unset;\n",
        "      animation: unset;\n",
        "    }\n",
        "\n",
        "  </style>\n",
        "\n",
        "  <button onclick=\"handleButtonClick()\">Show Result</button>\n",
        "\n",
        "  <script>\n",
        "      // Function to handle button click\n",
        "      function handleButtonClick() {\n",
        "          google.colab.kernel.invokeFunction('open_Train_Prediction_Conclusion_Page', [], {});\n",
        "      }\n",
        "  </script>\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WZz3QU-MLIi8"
      },
      "source": [
        "### Conclusion Page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaROVIuILLIu"
      },
      "outputs": [],
      "source": [
        "# Define the HTML, CSS, and JavaScript code for the GUI\n",
        "Conclusion_page_html_codeA = '''\n",
        "  <style>\n",
        "      body {\n",
        "          font-family: Arial, sans-serif;\n",
        "          text-align: center;\n",
        "          padding-top: 50px;\n",
        "      }\n",
        "      h1 {\n",
        "          color: #333333;\n",
        "      }\n",
        "      button {\n",
        "          background-color: #2D7DF6;\n",
        "          color: white;\n",
        "          padding: 10px 20px;\n",
        "          font-size: 16px;\n",
        "          border: none;\n",
        "          cursor: pointer;\n",
        "          border-radius: 4px;\n",
        "      }\n",
        "\n",
        "      /* style the output contaner:*/\n",
        "      #output-body .display_data:nth-child(4) {\n",
        "        text-align: left;\n",
        "        position: absolute;\n",
        "      }\n",
        "       #output-body .display_data:nth-child(5) {\n",
        "        text-align: right;\n",
        "      }\n",
        "  </style>\n",
        "\n",
        "  <h1>Temporal Link Prediction Model for Weighted Dynamic Networks</h1>\n",
        "  <h3> This system is able to predict the validity of links within a given article. </h4>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1lPkDK1Im6W1iosOTkSMntIFBs7cJqxni\" alt=\"progress-result\" width=\"150\" height=\"50\"/>\n",
        "  '''\n",
        "\n",
        "# Define the HTML, CSS, and JavaScript code for the GUI\n",
        "Conclusion_page_html_codeB = '''\n",
        "  <button onclick=\"handleButtonClick()\">Show Dataset</button>\n",
        "\n",
        "  <script>\n",
        "      // Function to handle button click\n",
        "      function handleButtonClick() {\n",
        "          google.colab.kernel.invokeFunction('open_Train_Prediction_Dataset_Page', [], {});\n",
        "      }\n",
        "  </script>\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ4gHGwZjDk0"
      },
      "source": [
        "### Show Dataset Page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmHSbAOyjIBG"
      },
      "outputs": [],
      "source": [
        "# Define the HTML, CSS, and JavaScript code for the GUI\n",
        "# Open the CSV file\n",
        "with open(metadata_csv_path, 'r') as file:\n",
        "\n",
        "    # Create a CSV reader object\n",
        "    csv_reader = csv.reader(file)\n",
        "\n",
        "    # Create an empty list to store the rows of data\n",
        "    data = []\n",
        "\n",
        "    # Iterate over each row in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Add each row to the data list\n",
        "        data.append(row)\n",
        "\n",
        "# Generate HTML table code dynamically\n",
        "html_code = '''\n",
        "  <style>\n",
        "    table {\n",
        "      border-collapse: collapse;\n",
        "      width: 100%;\n",
        "    }\n",
        "    th, td {\n",
        "      text-align: left;\n",
        "      padding: 8px;\n",
        "      border: 1px solid black;\n",
        "    }\n",
        "    tr:nth-child(1){\n",
        "      background-color: lightgray;\n",
        "    }\n",
        "    tr:hover {\n",
        "      background-color: lightgray;\n",
        "    }\n",
        "  </style>\n",
        "'''\n",
        "\n",
        "html_code += \"<table>\"\n",
        "# Add table header row with styling\n",
        "html_code += \"<tr>\"\n",
        "for header in data[0]:\n",
        "    html_code += f\"<th>{header}</th>\"\n",
        "html_code += \"</tr>\"\n",
        "\n",
        "# Add table data rows with styling\n",
        "for row in data[1:node_num]:\n",
        "    html_code += \"<tr>\"\n",
        "    for cell in row:\n",
        "        html_code += f\"<td>{cell}</td>\"\n",
        "    html_code += \"</tr>\"\n",
        "\n",
        "# Close the table\n",
        "html_code += \"</table>\"\n",
        "\n",
        "# # Display the HTML table\n",
        "# from IPython.display import display, HTML\n",
        "# display(HTML(html_code))\n",
        "\n",
        "show_dataset_page_html_code = '''\n",
        "  <style>\n",
        "      body {\n",
        "          font-family: Arial, sans-serif;\n",
        "          text-align: center;\n",
        "          padding-top: 50px;\n",
        "      }\n",
        "      h1 {\n",
        "          color: #333333;\n",
        "      }\n",
        "      button {\n",
        "          background-color: #2D7DF6;\n",
        "          color: white;\n",
        "          padding: 10px 20px;\n",
        "          font-size: 16px;\n",
        "          border: none;\n",
        "          cursor: pointer;\n",
        "          border-radius: 4px;\n",
        "      }\n",
        "  </style>\n",
        "\n",
        "  <h1>Temporal Link Prediction Model for Weighted Dynamic Networks</h1>\n",
        "  <h4> This system is able to predict the validity of links within a given article. </h4>\n",
        "'''\n",
        "\n",
        "show_dataset_page_html_code += html_code\n",
        "\n",
        "show_dataset_page_html_code += '''\n",
        "<button onclick=\"handleButtonClick()\">close</button>\n",
        "\n",
        "  <script>\n",
        "      // Function to handle button click\n",
        "      function handleButtonClick() {\n",
        "          google.colab.kernel.invokeFunction('close_page', [], {});\n",
        "      }\n",
        "  </script>\n",
        "  '''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_i7hcEm9L4Ir"
      },
      "source": [
        "## Run the GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awZeYmLMWrD4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Javascript, clear_output\n",
        "from IPython import get_ipython\n",
        "from google.colab import output\n",
        "import io\n",
        "from IPython.nbformat import current\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# MyDrive/Colab Notebooks/dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Register the Python function to be called when the button is clicked\n",
        "def open_Train_Prediction_DefineParams_Page():\n",
        "    clear_output()\n",
        "    display(HTML(Define_params_page_html_code))\n",
        "\n",
        "def open_Train_Prediction_RunNet_Page(selectedOptions, datasetURL):\n",
        "    # Specify that we modify the global variable\n",
        "    global pre_train_G_learning_rate\n",
        "    global G_learning_rate\n",
        "    global D_learning_rate\n",
        "    global clip_bound_number\n",
        "    global pre_epoch_num\n",
        "    global epoch_num\n",
        "    global time_num\n",
        "    global node_num\n",
        "    global max_thres\n",
        "\n",
        "    # update constanat parameters from the GUI paramerters:\n",
        "    time_num = int(selectedOptions[\"numTimeSlice\"])\n",
        "    pre_train_G_learning_rate = float(selectedOptions[\"learningRatePreTrain\"])\n",
        "    G_learning_rate = float(selectedOptions[\"learningRateG\"])\n",
        "    D_learning_rate = float(selectedOptions[\"learningRateD\"])\n",
        "    clip_bound_number = float(selectedOptions[\"clippingBound\"])\n",
        "    pre_epoch_num = int(selectedOptions[\"numEpochsPreTrain\"])\n",
        "    epoch_num = int(selectedOptions[\"numEpochsGAN\"])\n",
        "    max_thres = int(selectedOptions[\"weightRange\"])\n",
        "    node_num = int(selectedOptions[\"randomNodes\"])\n",
        "\n",
        "    if(datasetURL != \"\"):\n",
        "      global metadata_csv_path\n",
        "      metadata_csv_path = datasetURL\n",
        "\n",
        "    clear_output()\n",
        "    display(HTML(Run_Network_page_html_code))\n",
        "    # network celles\n",
        "    run_cells_range(18, 22)\n",
        "\n",
        "\n",
        "def open_Train_Prediction_Conclusion_Page():\n",
        "    clear_output()\n",
        "    display(HTML(Conclusion_page_html_codeA))\n",
        "    # show graph output\n",
        "    run_cells_range(23, 28)\n",
        "    display(HTML(Conclusion_page_html_codeB))\n",
        "\n",
        "\n",
        "def open_Train_Prediction_Dataset_Page():\n",
        "    clear_output()\n",
        "    display(HTML(show_dataset_page_html_code))\n",
        "\n",
        "def close_page():\n",
        "    clear_output()\n",
        "\n",
        "def run_cells_range(start, end):\n",
        "  with io.open(\"/content/drive/MyDrive/Colab Notebooks/Final-Project.ipynb\") as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "  ip = get_ipython()\n",
        "  for i in range(start, end+1):\n",
        "    cell = nb.worksheets[0].cells[i]\n",
        "    # for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type != 'code':\n",
        "      continue\n",
        "    ip.run_cell(cell.input)\n",
        "\n",
        "\n",
        "# init the network\n",
        "run_cells_range(0, 17)\n",
        "# Call the function to run all cells, GUI cells\n",
        "run_cells_range(29, 42)\n",
        "\n",
        "\n",
        "\n",
        "output.register_callback('open_Train_Prediction_DefineParams_Page', open_Train_Prediction_DefineParams_Page)\n",
        "output.register_callback('open_Train_Prediction_RunNet_Page', open_Train_Prediction_RunNet_Page)\n",
        "output.register_callback('open_Train_Prediction_Conclusion_Page', open_Train_Prediction_Conclusion_Page)\n",
        "output.register_callback('open_Train_Prediction_Dataset_Page', open_Train_Prediction_Dataset_Page)\n",
        "output.register_callback('close_page', close_page)\n",
        "\n",
        "# Display the GUI in the Colab notebook\n",
        "clear_output()\n",
        "display(HTML(Home_page_html_code))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5G5fw0kTCG1V",
        "DRvACAl0Dikr",
        "CpuvN3a906A7",
        "FWReMXJZ1Fix",
        "nT6cYmg0EABB",
        "o5hy9x6w_e5r",
        "zI9DZ8gwGkfx",
        "z3TDISVybazX",
        "WZz3QU-MLIi8",
        "OQ4gHGwZjDk0"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
